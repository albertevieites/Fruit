{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:39.742892097Z",
     "start_time": "2023-10-01T20:05:39.582826706Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/raw/entrenamiento.xlsx\")\n",
    "df = df.rename(columns={\"C7.1\": \"C8\", \"des\": \"QUALITY\"})\n",
    "features = df.drop(columns=[\"QUALITY\"])\n",
    "target = df[\"QUALITY\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:39.965052809Z",
     "start_time": "2023-10-01T20:05:39.629042646Z"
    }
   },
   "id": "89f565dc104d541a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "count    3646.000000\nmean        0.994044\nstd         0.003008\nmin         0.987110\n25%         0.991760\n50%         0.993800\n75%         0.996100\nmax         1.038980\nName: C8, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the values in column C8 that are above 900 by dividing them by 1000\n",
    "high_values = df[\"C8\"] > 900\n",
    "df.loc[high_values, \"C8\"] = df.loc[high_values, \"C8\"] / 1000\n",
    "\n",
    "# Display the basic statistics of the corrected column\n",
    "df[\"C8\"].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:40.013284105Z",
     "start_time": "2023-10-01T20:05:39.967417825Z"
    }
   },
   "id": "73c8ad2e7af00ab9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Imputar datos faltantes con la mediana\n",
    "for col in df.columns:\n",
    "    median_value = df[col].median()\n",
    "    df[col].fillna(median_value, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:40.013369492Z",
     "start_time": "2023-10-01T20:05:40.013080250Z"
    }
   },
   "id": "299c5c3691b3b897"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def impute_outliers_gmm(data):\n",
    "    gmm = GaussianMixture(n_components=4)\n",
    "    gmm_fit = gmm.fit(data)\n",
    "    densities = gmm.score_samples(data)\n",
    "    \n",
    "    # Identify outliers using a threshold\n",
    "    outliers = densities < np.percentile(densities, 5)\n",
    "    \n",
    "    # Impute outliers with the median of the entire data (you can adapt this if needed)\n",
    "    for column in data.columns:\n",
    "        data.loc[outliers, column] = data[column].median()\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "df_imputed_outliers = df.copy()\n",
    "df_imputed_outliers = impute_outliers_gmm(df_imputed_outliers)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:40.223444570Z",
     "start_time": "2023-10-01T20:05:40.013148848Z"
    }
   },
   "id": "23c8898f3bfa0f03"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X = df_imputed_outliers.drop(columns=['QUALITY'])\n",
    "y = df_imputed_outliers['QUALITY']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:40.269124215Z",
     "start_time": "2023-10-01T20:05:40.227973188Z"
    }
   },
   "id": "415aabfeb38bd84"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Random Forest: 0.1739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    max_depth=30,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    random_state=42)\n",
    "rf.fit(X_train_std, y_train)\n",
    "predictions_rf = rf.predict(X_train_std)\n",
    "mae_rf = mean_absolute_error(y_train, predictions_rf)\n",
    "print(f\"MAE for Random Forest: {mae_rf:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:41.567524160Z",
     "start_time": "2023-10-01T20:05:40.269040747Z"
    }
   },
   "id": "9286dd696f31ffa"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Gradient Boosting Regression: 0.2389\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros optimizados\n",
    "gb_model_std = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=3,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    subsample=0.9,\n",
    "    random_state=42)  # Puedes ajustar los hiperparámetros según sea necesario\n",
    "gb_model_std.fit(X_train_std, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de entrenamiento\n",
    "y_train_pred_gb = gb_model_std.predict(X_train_std)\n",
    "\n",
    "# Calcular el MAE para las predicciones\n",
    "mae_gb_std = mean_absolute_error(y_train, y_train_pred_gb)\n",
    "print(f'MAE of Gradient Boosting Regression: {mae_gb_std:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:41.845179241Z",
     "start_time": "2023-10-01T20:05:41.561551122Z"
    }
   },
   "id": "3e671b73880396af"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of XGBoost: 0.1247\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                 subsample=0.8,\n",
    "                                 min_child_weight=4,\n",
    "                                 max_depth=9,\n",
    "                                 learning_rate=0.1,\n",
    "                                 gamma=0,\n",
    "                                 colsample_bytree=0.8,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos estandarizados\n",
    "optimized_xgb.fit(X_train_std, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de entrenamiento\n",
    "xgb_optimized_predictions = optimized_xgb.predict(X_train_std)\n",
    "\n",
    "# Calcular el MAE\n",
    "mae_optimized_xgb = mean_absolute_error(y_train, xgb_optimized_predictions)\n",
    "mae_optimized_xgb\n",
    "print(f'MAE of XGBoost: {mae_optimized_xgb:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:42.102196690Z",
     "start_time": "2023-10-01T20:05:41.843693471Z"
    }
   },
   "id": "fd49cf7ff6378f09"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking Regressor: 0.173364\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "base_learners = [\n",
    "    ('rf', RandomForestRegressor(max_depth=30,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_samples_split=2,\n",
    "                                 n_estimators=100,\n",
    "                                 bootstrap=True,\n",
    "                                 random_state=42)),\n",
    "    ('gboost', GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                         max_depth=7,\n",
    "                                         max_features='sqrt',\n",
    "                                         min_samples_leaf=3,\n",
    "                                         min_samples_split=2,\n",
    "                                         n_estimators=100,\n",
    "                                         subsample=0.9,\n",
    "                                         random_state=42)),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror',\n",
    "                         subsample=0.8,\n",
    "                         min_child_weight=4,\n",
    "                         max_depth=9,\n",
    "                         learning_rate=0.1,\n",
    "                         gamma=0,\n",
    "                         colsample_bytree=0.8,\n",
    "                         random_state=42))\n",
    "]\n",
    "\n",
    "# Inicializa el modelo de Stacking\n",
    "stack_reg = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LinearRegression(),\n",
    "    cv=5  # Utiliza validación cruzada con 5 folds para entrenar los modelos base\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "stack_reg.fit(X_test_std, y_test)\n",
    "\n",
    "# Predict on the training set\n",
    "stacked_train_predictions = stack_reg.predict(X_test_std)\n",
    "\n",
    "# Calculate the MAE for the Stacking Regressor\n",
    "mae_stacked = mean_absolute_error(y_test, stacked_train_predictions)\n",
    "print(f'MAE of Stacking Regressor: {mae_stacked:.6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:05:44.664134123Z",
     "start_time": "2023-10-01T20:05:42.099568991Z"
    }
   },
   "id": "a3054dce8431c157"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
