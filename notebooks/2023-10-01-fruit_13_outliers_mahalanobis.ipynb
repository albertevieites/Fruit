{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:53:45.926519342Z",
     "start_time": "2023-10-01T19:53:45.695972760Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/raw/entrenamiento.xlsx\")\n",
    "df = df.rename(columns={\"C7.1\": \"C8\", \"des\": \"QUALITY\"})\n",
    "features = df.drop(columns=[\"QUALITY\"])\n",
    "target = df[\"QUALITY\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:53:46.062535023Z",
     "start_time": "2023-10-01T19:53:45.737036902Z"
    }
   },
   "id": "89f565dc104d541a"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "count    3646.000000\nmean        0.994044\nstd         0.003008\nmin         0.987110\n25%         0.991760\n50%         0.993800\n75%         0.996100\nmax         1.038980\nName: C8, dtype: float64"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the values in column C8 that are above 900 by dividing them by 1000\n",
    "high_values = df[\"C8\"] > 900\n",
    "df.loc[high_values, \"C8\"] = df.loc[high_values, \"C8\"] / 1000\n",
    "\n",
    "# Display the basic statistics of the corrected column\n",
    "df[\"C8\"].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:53:46.071115042Z",
     "start_time": "2023-10-01T19:53:46.064791683Z"
    }
   },
   "id": "73c8ad2e7af00ab9"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Imputar datos faltantes con la mediana\n",
    "for col in df.columns:\n",
    "    median_value = df[col].median()\n",
    "    df[col].fillna(median_value, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:53:46.128396997Z",
     "start_time": "2023-10-01T19:53:46.070162768Z"
    }
   },
   "id": "299c5c3691b3b897"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def impute_outliers_mahalanobis(data):\n",
    "    # Calculate the inverse of the covariance matrix\n",
    "    inv_covmat = np.linalg.inv(np.cov(data, rowvar=0))\n",
    "    \n",
    "    # Calculate the Mahalanobis distance for each observation\n",
    "    mean_data = np.mean(data, axis=0).values.reshape(1, -1)\n",
    "    mahal = distance.cdist(data, mean_data, 'mahalanobis', VI=inv_covmat)\n",
    "    mahal = mahal.flatten()\n",
    "    \n",
    "    # Identify outliers using a threshold\n",
    "    outliers = mahal > np.mean(mahal) + 3 * np.std(mahal)\n",
    "    \n",
    "    # Impute outliers with the median of the entire data\n",
    "    for column in data.columns:\n",
    "        data.loc[outliers, column] = data[column].median()\n",
    "    return data\n",
    "\n",
    "df_imputed_outliers = df.copy()\n",
    "df_imputed_outliers = impute_outliers_mahalanobis(df_imputed_outliers)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:02:54.190649841Z",
     "start_time": "2023-10-01T20:02:54.159221361Z"
    }
   },
   "id": "23c8898f3bfa0f03"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X = df_imputed_outliers.drop(columns=['QUALITY'])\n",
    "y = df_imputed_outliers['QUALITY']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:02:57.931986258Z",
     "start_time": "2023-10-01T20:02:57.878412236Z"
    }
   },
   "id": "415aabfeb38bd84"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Random Forest: 0.1831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    max_depth=30,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    random_state=42)\n",
    "rf.fit(X_train_std, y_train)\n",
    "predictions_rf = rf.predict(X_train_std)\n",
    "mae_rf = mean_absolute_error(y_train, predictions_rf)\n",
    "print(f\"MAE for Random Forest: {mae_rf:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:03:01.102886282Z",
     "start_time": "2023-10-01T20:02:59.857477452Z"
    }
   },
   "id": "9286dd696f31ffa"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Gradient Boosting Regression: 0.2641\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros optimizados\n",
    "gb_model_std = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=3,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    subsample=0.9,\n",
    "    random_state=42)  # Puedes ajustar los hiperparámetros según sea necesario\n",
    "gb_model_std.fit(X_train_std, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de entrenamiento\n",
    "y_train_pred_gb = gb_model_std.predict(X_train_std)\n",
    "\n",
    "# Calcular el MAE para las predicciones\n",
    "mae_gb_std = mean_absolute_error(y_train, y_train_pred_gb)\n",
    "print(f'MAE of Gradient Boosting Regression: {mae_gb_std:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:03:03.409913168Z",
     "start_time": "2023-10-01T20:03:03.119524979Z"
    }
   },
   "id": "3e671b73880396af"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of XGBoost: 0.1378\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                 subsample=0.8,\n",
    "                                 min_child_weight=4,\n",
    "                                 max_depth=9,\n",
    "                                 learning_rate=0.1,\n",
    "                                 gamma=0,\n",
    "                                 colsample_bytree=0.8,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos estandarizados\n",
    "optimized_xgb.fit(X_train_std, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de entrenamiento\n",
    "xgb_optimized_predictions = optimized_xgb.predict(X_train_std)\n",
    "\n",
    "# Calcular el MAE\n",
    "mae_optimized_xgb = mean_absolute_error(y_train, xgb_optimized_predictions)\n",
    "mae_optimized_xgb\n",
    "print(f'MAE of XGBoost: {mae_optimized_xgb:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:03:06.169875149Z",
     "start_time": "2023-10-01T20:03:06.000437350Z"
    }
   },
   "id": "fd49cf7ff6378f09"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking Regressor: 0.168375\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "base_learners = [\n",
    "    ('rf', RandomForestRegressor(max_depth=30,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_samples_split=2,\n",
    "                                 n_estimators=100,\n",
    "                                 bootstrap=True,\n",
    "                                 random_state=42)),\n",
    "    ('gboost', GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                         max_depth=7,\n",
    "                                         max_features='sqrt',\n",
    "                                         min_samples_leaf=3,\n",
    "                                         min_samples_split=2,\n",
    "                                         n_estimators=100,\n",
    "                                         subsample=0.9,\n",
    "                                         random_state=42)),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror',\n",
    "                         subsample=0.8,\n",
    "                         min_child_weight=4,\n",
    "                         max_depth=9,\n",
    "                         learning_rate=0.1,\n",
    "                         gamma=0,\n",
    "                         colsample_bytree=0.8,\n",
    "                         random_state=42))\n",
    "]\n",
    "\n",
    "# Inicializa el modelo de Stacking\n",
    "stack_reg = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LinearRegression(),\n",
    "    cv=5  # Utiliza validación cruzada con 5 folds para entrenar los modelos base\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "stack_reg.fit(X_test_std, y_test)\n",
    "\n",
    "# Predict on the training set\n",
    "stacked_train_predictions = stack_reg.predict(X_test_std)\n",
    "\n",
    "# Calculate the MAE for the Stacking Regressor\n",
    "mae_stacked = mean_absolute_error(y_test, stacked_train_predictions)\n",
    "print(f'MAE of Stacking Regressor: {mae_stacked:.6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:03:11.417334326Z",
     "start_time": "2023-10-01T20:03:08.412314750Z"
    }
   },
   "id": "a3054dce8431c157"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
