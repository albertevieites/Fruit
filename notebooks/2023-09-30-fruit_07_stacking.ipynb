{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:16.493617995Z",
     "start_time": "2023-09-30T21:41:16.093701239Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df= pd.read_excel(\"../data/raw/entrenamiento.xlsx\")\n",
    "df= df.rename(columns={\"C7.1\": \"C8\", \"des\": \"QUALITY\"})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:18.667062235Z",
     "start_time": "2023-09-30T21:41:18.118976141Z"
    }
   },
   "id": "4a09fb42ffab4d39"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "high_values_train = df[\"C8\"] > 900\n",
    "df.loc[high_values_train, \"C8\"] = df.loc[high_values_train, \"C8\"] / 1000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:19.365431518Z",
     "start_time": "2023-09-30T21:41:19.354838534Z"
    }
   },
   "id": "25da9e9f818f17c1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def impute_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "\n",
    "    # Impute outliers with the median of the column\n",
    "    data.loc[outliers, column] = data[column].median()\n",
    "    return data\n",
    "\n",
    "\n",
    "# Impute outliers in the dataset using IQR method\n",
    "df_imputed_outliers = df.copy()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype != 'object':  # Apply only for numerical columns\n",
    "        df_imputed_outliers = impute_outliers_iqr(df_imputed_outliers, column)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:20.519897058Z",
     "start_time": "2023-09-30T21:41:20.499972186Z"
    }
   },
   "id": "fe8ac01ae1c5cd61"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Series([], dtype: int64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values using median for predictor columns (excluding 'des' or 'QUALITY')\n",
    "for column in df_imputed_outliers.columns:\n",
    "    if column != \"des\" and df_imputed_outliers[\n",
    "        column].dtype != 'object':  # Exclude target column and non-numerical columns\n",
    "        median_value = df_imputed_outliers[column].median()\n",
    "        df_imputed_outliers[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# Check if there are any missing values left\n",
    "remaining_missing_values = df_imputed_outliers.isnull().sum()\n",
    "remaining_missing_values[remaining_missing_values > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:22.714575320Z",
     "start_time": "2023-09-30T21:41:22.697359861Z"
    }
   },
   "id": "e2a6eec9e963cd0e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_completed = df_imputed_outliers.copy()\n",
    "# Separar las características y la variable objetivo\n",
    "X = df_completed.drop(\"QUALITY\", axis=1)\n",
    "y = df_completed[\"QUALITY\"]\n",
    "\n",
    "# Estandarizar las características\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "## Splitting the DataFrame\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_std, X_test_std, y_train, y_test = train_test_split(X_standardized, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:41:34.027997845Z",
     "start_time": "2023-09-30T21:41:33.997273923Z"
    }
   },
   "id": "4a0c5927d77392e6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) del Stacking Regressor: 0.1216\n",
      "MAE scores from cross-validation: [0.47086998 0.47505819 0.47429711 0.45613098 0.48134349]\n",
      "Mean MAE score: 0.47153994875048877\n",
      "Standard Deviation of MAE scores: 0.008413972631977733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Definir los modelos base con sus hiperparámetros optimizados\n",
    "base_models = [\n",
    "    (\"xgb\", xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        subsample=0.8,\n",
    "        n_estimators=200,\n",
    "        min_child_weight=1,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        gamma=0,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )),\n",
    "    (\"rf\", RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_depth=None,\n",
    "        bootstrap=True,\n",
    "        random_state=42\n",
    "    )),\n",
    "    (\"gb\", GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        max_features=None,\n",
    "        n_estimators=200,\n",
    "        subsample=0.9,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Inicializar el Stacking Regressor con los modelos base y una regresión lineal como meta-modelo\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Entrenar el modelo de Stacking\n",
    "stacked_model.fit(X_train_std, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de entrenamiento\n",
    "stacked_train_predictions = stacked_model.predict(X_train_std)\n",
    "\n",
    "# Calcular el MAE para el Stacking Regressor\n",
    "mae_stacked = mean_absolute_error(y_train, stacked_train_predictions)\n",
    "print(f\"Mean Absolute Error (MAE) del Stacking Regressor: {mae_stacked:.4f}\")\n",
    "\n",
    "# Para validación cruzada\n",
    "scores = -cross_val_score(stacked_model, X_train_std, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"MAE scores from cross-validation: {scores}\")\n",
    "print(f\"Mean MAE score: {scores.mean()}\")\n",
    "print(f\"Standard Deviation of MAE scores: {scores.std()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-30T21:47:30.597907027Z",
     "start_time": "2023-09-30T21:46:17.455540022Z"
    }
   },
   "id": "f5ec878301444c33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
